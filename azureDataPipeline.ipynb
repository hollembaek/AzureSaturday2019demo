{"cells":[{"cell_type":"code","source":["# from stripogram import HTML2Text\nfrom bs4 import BeautifulSoup\nimport requests\nimport os\n\n# libs for storage account\n# import os # import OS dependant functionality\nimport pandas as pd  # import data analysis library required\nfrom azure.storage.blob import BlockBlobService\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# Blob storage Settings configs\nblob_account_name = \"your blob here\"  # fill in your blob account name\nblob_account_key = \"your key here"  # fill in your blob account key\nmycontainer = \"your container here\"  # fill in the container name\nmyblobname = \"TestData_semi.txt\"  # fill in the blob name semicolon delimited\nmydatafile = \"TestData_semi.txt\"  # fill in the output file name\nmyoutputfile = \"TestData_semi_out.txt\"\n\n# cognitive service configs\nsubscription_key_cognitive_service = \"your key here\"  #\nassert subscription_key_cognitive_service\ntext_analytics_base_url = \"https://westeurope.api.cognitive.microsoft.com/text/analytics/v2.0/\"  # update it from panel settings\nsubscription_key_translation_service = \"your key here\"\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["dtype_dic = {'SourceText': str, 'EnglishText': str, 'Entities': str, 'KeyPhrases':str}\n\ndef readfile():\n    blob_service = BlockBlobService(account_name=blob_account_name, account_key=blob_account_key)\n    blob_service.get_blob_to_path(mycontainer, myblobname, mydatafile)\n    mydata = pd.read_csv(mydatafile, header=0, sep=\";\",dtype=dtype_dic)\n    return mydata\n\n\ndef read_localfile():\n    dtype_dic = {'SourceText': str, 'EnglishText': str, 'Entities': str, 'KeyPhrases':str}\n    return pd.read_csv(mydatafile, header=0, sep=\";\", dtype=dtype_dic)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# core logic goes here\ndef getWebsiteText(website_url):\n    rsp = requests.get(website_url)\n    # print(rsp.text)\n    soup = BeautifulSoup(rsp.text)\n    # print(\" \".join(soup.strings))\n    body = soup.find('body')  # .get_text()\n\n    # remove script tags\n    [x.extract() for x in body.findAll('script')]\n    body_text = \" \".join(body.strings)\n    # print(body_text.strip())\n    return body_text.strip()\n\n\n# 1 Detect language\ndef get_language(body_text):\n    language_api_url = text_analytics_base_url + \"languages\"\n    #print(language_api_url)\n    documents = {'documents': [{'id': '1', 'text': body_text}]}\n\n    headers = {\"Ocp-Apim-Subscription-Key\": subscription_key_cognitive_service}\n    response = requests.post(language_api_url, headers=headers, json=documents)\n    languages = response.json()\n    #print(languages)\n    lang = languages['documents'][0]['detectedLanguages'][0]['iso6391Name']  # error prone\n    #print(lang)\n    return lang\n\n\n# 3 Key Phrase Extraction\ndef get_keyphrases(body_text, lang):\n    key_phrase_api_url = text_analytics_base_url + \"keyPhrases\"\n    documents = {'documents': [\n        {'id': '1', 'language': lang, 'text': body_text}\n    ]}\n\n    headers = {'Ocp-Apim-Subscription-Key': subscription_key_cognitive_service}\n    response = requests.post(key_phrase_api_url, headers=headers, json=documents)\n    key_phrases = response.json()\n    if key_phrases and 'documents' in key_phrases and 'keyPhrases' in key_phrases['documents'][0]:\n        #print(key_phrases['documents'][0]['keyPhrases'])\n        return key_phrases['documents'][0]['keyPhrases']\n\n\n# 4 Named Entity Recognition\ndef get_named_entities(body_text):\n    entity_linking_api_url = text_analytics_base_url + \"entities\"\n    documents = {'documents': [\n        {'id': '1', 'text': body_text}\n    ]}\n    headers = {\"Ocp-Apim-Subscription-Key\": subscription_key_cognitive_service}\n    response = requests.post(entity_linking_api_url, headers=headers, json=documents)\n    entities = response.json()\n    if entities and 'documents' in entities and 'entities' in entities['documents'][0]:\n        #print(entities['documents'][0]['entities'])\n        return entities['documents'][0]['entities']\n\n\n# 2 Translation\ndef translate_text(body_text, lang_from, lang_to):\n    api_url = \"https://api.cognitive.microsofttranslator.com/translate?api-version=3.0&to={1}\" \\\n        .format(text_analytics_base_url, lang_to)\n\n    body = [{\n        'text': body_text\n    }]\n\n    headers = {\n        'Ocp-Apim-Subscription-Key': subscription_key_translation_service,\n        'Content-type': 'application/json',\n        # 'X-ClientTraceId': str(uuid.uuid4())\n    }\n    try:\n        request = requests.post(api_url, headers=headers, json=body)\n        response = request.json()\n\n        if len(response) > 0:\n            response = response[0]\n\n        if response and 'translations' in response and 'text' in response['translations'][0]:\n            #print(response['translations'][0]['text'])\n            return response['translations'][0]['text']\n    except Exception as ex:\n        print(ex)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["def write_output_file(df_data, file_name):\n  df_data.to_csv(os.path.join(os.getcwd(),file_name), encoding='utf-8', index=False)\n  localfileprocessed = os.path.join(os.getcwd(),file_name) #assuming file is in current working directory\n  #print(localfileprocessed)\n  blob_service = BlockBlobService(account_name=blob_account_name, account_key=blob_account_key)\n\n  try:\n   #perform upload\n   blob_service.create_blob_from_path(mycontainer,file_name,localfileprocessed)\n  except Exception as ex:\t        \n       print (ex)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["def run_pipeline():\n  data = readfile()  # readfile()\n  for index, row in data.iterrows():\n      try:\n\n          website_url = row['website']#\"http://praiaazul.com/\"  # row['website']\n          print(website_url)\n          # 1. browse the website and store the native text\n          body_text = getWebsiteText(website_url)\n          #print(body_text)\n          if body_text:\n              data.at[index, 'SourceText'] = body_text\n\n          # check language and store translated text if language is different than english\n          lang = get_language(body_text)\n          if 'en' not in lang:\n              translated = translate_text(body_text, lang, 'en')\n              #print(translated)\n              data.at[index, 'EnglishText'] = translated\n\n          # Get the keyphrases and store them\n          keyphrases = get_keyphrases(body_text, lang)\n          if keyphrases:\n              data.at[index, 'KeyPhrases'] = \", \".join(keyphrases)\n\n          # get the named entites and update the file\n          named_entites = get_named_entities(body_text)\n          if named_entites:\n              entity_name_only= []\n              for entity in named_entites:\n                  entity_name_only.append(entity['name'])\n              data.at[index, 'Entities'] = \", \".join(entity_name_only)\n\n      except Exception as ex:\n          print(ex)\n\n  # write them back to a file\n  write_output_file(data, myoutputfile)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["try:\n  run_pipeline()\n  print('Finished')\nexcept Exception as ex:\n  print(ex)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">http://praiaazul.com/\nFinished\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/driver/outputfile_.csv\n</div>"]}}],"execution_count":9}],"metadata":{"name":"azureDataPipeline","notebookId":4488907975325800},"nbformat":4,"nbformat_minor":0}
